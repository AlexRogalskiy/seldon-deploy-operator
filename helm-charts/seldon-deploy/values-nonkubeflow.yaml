
replicaCount: 1

image:
  image: seldonio/seldon-deploy:0.0.0
  pullPolicy: Always

loadtest:
  image: seldonio/hey-loadtester:0.1

alibidetect:
  image: seldonio/alibi-detect-server:0.0.1

nameOverride: ""
fullnameOverride: ""

service:
  type: ClusterIP
  port: 80

# boolean to enable app-level auth (defaults to "false")
enableAppAuth: true

# boolean to enable app-analytics (defaults to "true")
enableAppAnalytics: true

env:
  GITOPS_FORMAT: "json"
  USERID_CLAIM_KEY: "preferred_username" # claim to be used as userid (defaults to "preferred_username")
  OIDC_PROVIDER: "" # oidc issuerURL
  CLIENT_ID: "deploy-server" # oidc client ID
  CLIENT_SECRET: "deploy-secret" # oidc client secret
  REDIRECT_URL: "" #`${oidc_redirect_url}/seldon-deploy/auth/callback`
  OIDC_SCOPES: "profile email groups" #oidc scopes (defaults to "profile email groups")
  # if enableAppAnalytics enabled use token
  # APP_ANALYTICS_TOKEN: ""

docker:
  user: "unkown"

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []

  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

serviceAccount:
  create: true

github:
  user: ""
  token: ""
  email: ""

kfserving:
  protocol: "http"
  enabled: true
  #Change ip to hostname on AWS. Or put real cluster IP after install.
  curlForm: |
    MODEL_NAME={{ .ModelName }}<br>
    CLUSTER_IP=$(kubectl -n {{ .IngressNamespace }} get service {{ .IngressServiceName }} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')<br>
    SERVICE_HOSTNAME=$(kubectl get inferenceservice {{ .ModelName }} -o jsonpath='{.status.url}' | cut -d "/" -f 3)<br>
    curl -v -H "Host: ${SERVICE_HOSTNAME}" {{ .KfServingProtocol }}://$CLUSTER_IP/v1/models/$MODEL_NAME:predict -d '{{ .Payload }}'
  #Form for cluster-internal calls.
  requestForm: "{{ .KfServingProtocol }}://{{ .IngressServiceName }}/v1/models/{{ .ModelName }}:predict"
  explainForm: "{{ .KfServingProtocol }}://{{ .IngressServiceName }}/v1/models/{{ .ModelName }}:explain"

seldon:
  protocol: "http"
  enabled: true
  #Below are templates that can be changed to adjust how requests are made and what curl option is shown to user.
  #Change ip to hostname on AWS. Or put real cluster IP after install. Shown to user for calls outside cluster.
  curlForm: |
    CLUSTER_IP=$(kubectl -n {{ .IngressNamespace }} get service {{ .IngressServiceName }} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')<br>
    curl -k -H "X-Auth-Token: {{ .Token }} " -H "Content-Type: application/json" {{ .SeldonProtocol }}://$CLUSTER_IP/seldon/{{ .Namespace }}/{{ .ModelName }}/api/v0.1/predictions -d '{{ .Payload }}'
  tensorFlowCurlForm: |
    CLUSTER_IP=$(kubectl -n {{ .IngressNamespace }} get service {{ .IngressServiceName }} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')<br>
    curl -k -H "X-Auth-Token: {{ .Token }} " -H "Content-Type: application/json" {{ .SeldonProtocol }}://$CLUSTER_IP/seldon/{{ .Namespace }}/{{ .ModelName }}/v1/models/:predict -d '{{ .Payload }}'
  #Forms for cluster-internal calls.
  #e.g. could be changed to skip ingress by setting to "http://{{ .ModelName }}-{{ .ModelName }}-{{ .Predictor }}.{{ .Namespace }}:8000/api/v0.1/predictions"
  seldonRequestForm: "{{ .SeldonProtocol }}://{{ .IngressServiceName }}/seldon/{{ .Namespace }}/{{ .ModelName }}/api/v0.1/predictions"
  tensorflowRequestForm: "{{ .SeldonProtocol }}://{{ .IngressServiceName }}/seldon/{{ .Namespace }}/{{ .ModelName }}/v1/models/:predict"
  #explainer call for seldon can go straight to predictor rather than ingress as not worried about loadbalancing a canary
  explainForm: "http://{{ .ModelName }}-{{ .Predictor }}-explainer.{{ .Namespace }}:9000/v1/models/{{ .ModelName }}:explain"

external:
  protocol: "http"

serviceAccountName: seldon-deploy

ingressGateway:
  seldonIngressService: "istio-ingressgateway"
  kfServingIngressService: "istio-ingressgateway"
  ingressNamespace: "istio-system"

virtualService:
  create: true
  prefix: "/seldon-deploy/"
  gateways:
    - seldon-gateway.istio-system.svc.cluster.local

rbac:
  create: true
  clusterWide: false

nodeSelector: {}

tolerations: []

affinity: {}

imagePullSecrets:
  - name: regcred

skipVerifyGit: true
skipVerifyHttpCalls: true


prometheus:
  seldon:
    url: "http://seldon-core-analytics-prometheus-seldon.seldon-system/api/v1/"
    # resource metrics may come from different prometheus than req metrics - set only if different
    # resourceMetricsUrl: ""
    # see https://github.com/openshift/cluster-monitoring-operator/issues/768
    namespaceMetricName: "kubernetes_namespace"
    serviceMetricName: "service"
    #leave below empty/commented for prom without token-based auth
    #basic auth can be handled by putting user:pass in url.
    #jwtSecretName: "jwt-elastic"
    #jwtSecretKey: "jwt-elastic.txt"
  knative:
    url: "http://prometheus-system-np.knative-monitoring.svc.cluster.local:8080/api/v1/"


elasticsearch:
  url: "http://elasticsearch-master.seldon-logs.svc.cluster.local:9200"
  #leave below empty/commented for elastic without token-based auth
  #basic auth can be handled by putting user:pass in urls.elasticsearch
  #jwtSecretName: "jwt-elastic"
  #jwtSecretKey: "jwt-elastic.txt"

argocd:
  url: "https://argocd-server.argocd.svc.cluster.local"
